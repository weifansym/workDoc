## 超时控制
超时控制，我们的组件能够快速失效（fail fast），因为我们不希望等到断开的实例直到超时。没有什么比挂起的请求和无响应的界面更令人失望。这不仅浪费资源，而且还会让用户体验变得更差。
我们的服务是互相调用的，所以在这些延迟叠加前，应该特别注意防止那些超时的操作。

![image](https://user-images.githubusercontent.com/6757408/194708245-aaf40306-d6a8-45b0-8556-732288933ec3.png)

* 网路传递具有不确定性。
* 客户端和服务端不一致的超时策略导致资源浪费。
* “默认值”策略。
* 高延迟服务导致 c*lient 浪费资源等待，使用超时传递:* 进程间传递 + 跨进程传递。

> 超时控制是微服务可用性的第一道关，良好的超时策略，可以尽可能让服务不堆积请求，尽快清空高延迟的请求，释放 Goroutine。
> 建议：内网请求一般不超过100ms，公网请求一般不超过1s。

----
实际业务开发中，我们依赖的微服务的超时策略并不清楚，或者随着业务迭代耗时超生了变化，意外的导致依赖者出现了超时。
* 服务提供者定义好 latency SLO，更新到 gRPC Proto 定义中，服务后续迭代，都应保证 SLO。
![image](https://user-images.githubusercontent.com/6757408/194708316-ef4a7498-b09d-4413-9391-83ee3fa1bef4.png)

避免出现意外的默认超时策略，或者意外的配置超时策略。
* kit 基础库兜底默认超时，比如 100ms，进行配置防御保护，避免出现类似 60s 之类的超大超时策略。
* 配置中心公共模版，对于未配置的服务使用公共配置。

```
package google.example.library.v1;

service LibraryService {
    // Lagency SLO: 95th in 100ms, 99th in 150ms.
    rpc CreateBook(CreateBookRequest) returns (Book); 
    rpc GetBook(GetBookRequest) returns Book);
    rpc ListBooks(ListBooksRequest) returns (ListBooksResponse);
}
```
----
#### 超时传递(连接超时、读超时、写超时)
当上游服务已经超时返回 504，但下游服务仍然在执行，会导致浪费资源做无用功。超时传递指的是把当前服务的剩余 Quota 传递到下游服务中，继承超时策略，控制请求级别的全局超时控制。

* 进程内超时控制

一个请求在每个阶段(**网络请求**)开始前，就要检查是否还有足够的剩余来处理请求，以及继承他的超时策略，使用Go标准库的[context.WithTimeout](https://pkg.go.dev/context)
![image](https://user-images.githubusercontent.com/6757408/194708431-9289f435-dba9-4a41-b723-0d2d928c501c.png)

读配置和context的超时，取小的进行设置

----
#### 跨进程超时控制
1.A gRPC 请求 B，1s超时。

2.B 使用了300ms 处理请求，再转发请求 C。

3.C 配置了600ms 超时，但是实际只用了500ms。

4.到其他的下游，发现余量不足，取消传递。

![image](https://user-images.githubusercontent.com/6757408/194708453-b6065c48-a969-47d8-a82f-2c80587d3721.png)

> 在需要强制执行时，下游的服务可以覆盖上游的超时传递和配额。
> 在 gRPC 框架中，会依赖 gRPC Metadata Exchange，基于 HTTP2 的 Headers 传递 grpc-timeout 字段，自动传递到下游，构建带 timeout 的 context。

----
* 双峰分布: 95%的请求耗时在100ms内，5%的请求可能永远不会完成（长超时）。
* 对于监控不要只看 mean，可以看看耗时分布统计，比如 95th，99th。
* 设置合理的超时，拒绝超长请求，或者当Server 不可用要主动失败。

![image](https://user-images.githubusercontent.com/6757408/194708498-d2b9d66c-67e7-4e7a-a1ed-5acc9d92b75d.png)

超时决定着服务线程耗尽。

----
### 超时-Case Study
* SLB 入口 Nginx 没配置超时导致连锁故障。
* 服务依赖的 DB 连接池漏配超时，导致请求阻塞，最终服务集体 OOM。
* 下游服务发版耗时增加，而上游服务配置超时过短，导致上游请求失败。





