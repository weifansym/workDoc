## 前言

本文先自上而下，后自底向上的介绍ElasticSearch的底层工作原理，试图回答以下问题：

-   为什么我的搜索 `*foo-bar*` 无法匹配 `foo-bar` ？
-   为什么增加更多的文件会压缩索引（Index）？
-   为什么ElasticSearch占用很多内存？

**版本**

elasticsearch版本: elasticsearch-2.2.0

## 图解ElasticSearch

-   云上的集群

<img width="1374" height="768" alt="image" src="https://github.com/user-attachments/assets/457578ba-d13c-499d-9d0e-cb9bc7600894" />

-   集群里的盒子

云里面的每个白色正方形的盒子代表一个节点——Node。

<img width="1368" height="764" alt="image" src="https://github.com/user-attachments/assets/665c0c2b-6cfa-4a9d-b6da-5cc2a09e5833" />

-   节点之间

在一个或者多个节点直接，多个绿色小方块组合在一起形成一个ElasticSearch的索引。

<img width="1372" height="762" alt="image" src="https://github.com/user-attachments/assets/8680803d-6cc4-45f7-b7ba-9c64f5f11a3d" />

-   索引里的小方块

在一个索引下，分布在多个节点里的绿色小方块称为分片——Shard。

<img width="1370" height="762" alt="image" src="https://github.com/user-attachments/assets/12bba2c3-01d3-4181-8e99-a3dc61d68c8d" />

-   Shard＝Lucene Index

一个ElasticSearch的Shard本质上是一个Lucene Index。

<img width="1370" height="762" alt="image" src="https://github.com/user-attachments/assets/7afb4a97-5b9d-4d76-b3f7-82b3320476c3" />

Lucene是一个Full Text 搜索库（也有很多其他形式的搜索库），ElasticSearch是建立在Lucene之上的。接下来的故事要说的大部分内容实际上是ElasticSearch如何基于Lucene工作的。

## 图解Lucene

### Segment

-   **Mini索引——segment**

在Lucene里面有很多小的segment，我们可以把它们看成Lucene内部的mini-index。

<img width="1372" height="758" alt="image" src="https://github.com/user-attachments/assets/c48f8345-b155-45bb-9a5e-81f46d388aee" />

-   Segment内部

（有着许多数据结构）

-   Inverted Index
-   Stored Fields
-   Document Values
-   Cache

<img width="1368" height="760" alt="image" src="https://github.com/user-attachments/assets/e6a109b5-94fe-48fd-8c47-7469d322ab9d" />

#### Inverted Index

最最重要的Inverted Index

<img width="1364" height="760" alt="image" src="https://github.com/user-attachments/assets/9a6fa61a-c0f4-44e1-a07b-6a1a456e6c27" />

Inverted Index主要包括两部分：

-   一个有序的数据字典Dictionary（包括单词Term和它出现的频率）。
-   与单词Term对应的Postings（即存在这个单词的文件）。

当我们搜索的时候，首先将搜索的内容分解，然后在字典里找到对应Term，从而查找到与搜索相关的文件内容。

<img width="1370" height="760" alt="image" src="https://github.com/user-attachments/assets/0cedaf18-db36-487d-9496-d31d85b835f3" />

-   **查询“the fury”**

<img width="1370" height="758" alt="image" src="https://github.com/user-attachments/assets/6c2fff54-cf35-4501-a92e-658e3f88378d" />

-   **自动补全**（AutoCompletion-Prefix）

如果想要查找以字母“c”开头的字母，可以简单的通过二分查找（Binary Search）在Inverted Index表中找到例如“choice”、“coming”这样的词（Term）。

<img width="1372" height="764" alt="image" src="https://github.com/user-attachments/assets/f3b838c3-0607-4cf4-8ac2-0d95272202ca" />

-   **昂贵的查找**

如果想要查找所有包含“our”字母的单词，那么系统会扫描整个Inverted Index，这是非常昂贵的。

<img width="1370" height="770" alt="image" src="https://github.com/user-attachments/assets/ebb75885-41ef-49b3-8e69-a34958229975" />

在此种情况下，如果想要做优化，那么我们面对的问题是如何生成合适的Term。

-   **问题的转化**

<img width="1376" height="772" alt="image" src="https://github.com/user-attachments/assets/0400540b-dca7-4d1a-a232-742be44ffe55" />

对于以上诸如此类的问题，我们可能会有几种可行的解决方案：

1.  `* suffix -> xiffus *`

如果我们想以后缀作为搜索条件，可以为Term做反向处理。

1.  `(60.6384, 6.5017) -> u4u8gyykk`

对于GEO位置信息，可以将它转换为GEO Hash。

1.  `123 -> {1-hundreds, 12-tens, 123}`

对于简单的数字，可以为它生成多重形式的Term。

-   **解决拼写错误**

一个Python库 为单词生成了一个包含错误拼写信息的树形状态机，解决拼写错误的问题。

<img width="1370" height="764" alt="image" src="https://github.com/user-attachments/assets/a0273b82-3387-4cba-845e-07b32e440387" />

#### Stored Field字段查找

当我们想要查找包含某个特定标题内容的文件时，Inverted Index就不能很好的解决这个问题，所以Lucene提供了另外一种数据结构Stored Fields来解决这个问题。本质上，Stored Fields是一个简单的键值对key-value。默认情况下，ElasticSearch会存储整个文件的JSON source。

<img width="1370" height="770" alt="image" src="https://github.com/user-attachments/assets/49ccd52c-d920-4a5d-b269-91df537d94a1" />

#### Document Values为了排序，聚合

即使这样，我们发现以上结构仍然无法解决诸如：排序、聚合、facet，因为我们可能会要读取大量不需要的信息。

所以，另一种数据结构解决了此种问题：Document Values。这种结构本质上就是一个列式的存储，它高度优化了具有相同类型的数据的存储结构。

<img width="1374" height="772" alt="image" src="https://github.com/user-attachments/assets/8f31d581-3591-4b9c-ba76-e47f976f29c9" />

为了提高效率，ElasticSearch可以将索引下某一个Document Value全部读取到内存中进行操作，这大大提升访问速度，但是也同时会消耗掉大量的内存空间。

总之，这些数据结构Inverted Index、Stored Fields、Document Values及其缓存，都在segment内部。

### 搜索发生时

搜索时，Lucene会搜索所有的segment然后将每个segment的搜索结果返回，最后合并呈现给客户。

Lucene的一些特性使得这个过程非常重要：

-   Segments是不可变的（immutable）
    -   Delete? 当删除发生时，Lucene做的只是将其标志位置为删除，但是文件还是会在它原来的地方，不会发生改变
    -   Update? 所以对于更新来说，本质上它做的工作是：先删除，然后重新索引（Re-index）
-   随处可见的压缩
    -   Lucene非常擅长压缩数据，基本上所有教科书上的压缩方式，都能在Lucene中找到。
-   缓存所有的所有
    -   Lucene也会将所有的信息做缓存，这大大提高了它的查询效率。

### 缓存的故事

当ElasticSearch索引一个文件的时候，会为文件建立相应的缓存，并且会定期（每秒）刷新这些数据，然后这些文件就可以被搜索到。

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/e3faac76-7e09-4eac-bc75-df6e72d648a2" />

随着时间的增加，我们会有很多segments，

<img width="1374" height="766" alt="image" src="https://github.com/user-attachments/assets/2ce5bcfb-fdba-4ba9-805d-0ce8ec577487" />

所以ElasticSearch会将这些segment合并，在这个过程中，segment会最终被删除掉

<img width="1378" height="768" alt="image" src="https://github.com/user-attachments/assets/e8e3a24f-fb57-42e5-a8fa-602a78cfd58e" />

这就是为什么增加文件可能会使索引所占空间变小，它会引起merge，从而可能会有更多的压缩。

-   **举个栗子**

有两个segment将会merge

<img width="1376" height="764" alt="image" src="https://github.com/user-attachments/assets/79ce314a-2641-472f-bc18-f369d16a69c1" />

这两个segment最终会被删除，然后合并成一个新的segment

<img width="1374" height="760" alt="image" src="https://github.com/user-attachments/assets/e20a859e-29b2-4489-8530-487270fa85d6" />

这时这个新的segment在缓存中处于cold状态，但是大多数segment仍然保持不变，处于warm状态。

以上场景经常在Lucene Index内部发生的。

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/a9769021-2ab4-492a-bcd9-7fc1fbf22da1" />

### 在Shard中搜索

ElasticSearch从Shard中搜索的过程与Lucene Segment中搜索的过程类似。

<img width="1374" height="760" alt="image" src="https://github.com/user-attachments/assets/48e52d46-32cd-457c-8589-0ef240c0ec19" />

与在Lucene Segment中搜索不同的是，Shard可能是分布在不同Node上的，所以在搜索与返回结果时，所有的信息都会通过网络传输。

需要注意的是：

1次搜索查找2个shard ＝ 2次分别搜索shard

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/9ef6e6f8-d69b-45e7-82a2-3b280ecce3e2" />

-   **对于日志文件的处理**

当我们想搜索特定日期产生的日志时，通过根据时间戳对日志文件进行分块与索引，会极大提高搜索效率。

当我们想要删除旧的数据时也非常方便，只需删除老的索引即可。

<img width="1374" height="766" alt="image" src="https://github.com/user-attachments/assets/4acbbec5-cb48-43e6-bed9-7ed9dcbb4066" />

在上种情况下，每个index有两个shards

-   **如何Scale**

<img width="1372" height="760" alt="image" src="https://github.com/user-attachments/assets/8b4a5b40-be2b-4d1f-878d-304950c19802" />

shard不会进行更进一步的拆分，但是shard可能会被转移到不同节点上

<img width="1372" height="760" alt="image" src="https://github.com/user-attachments/assets/9f3adaf2-1f92-40d9-9cbc-4b90e59498d7" />

所以，如果当集群节点压力增长到一定的程度，我们可能会考虑增加新的节点，这就会要求我们对所有数据进行重新索引，这是我们不太希望看到的，所以我们需要在规划的时候就考虑清楚，如何去平衡足够多的节点与不足节点之间的关系。

-   节点分配与Shard优化
    -   为更重要的数据索引节点，分配性能更好的机器
    -   确保每个shard都有副本信息replica

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/db7f5a2c-55ca-402c-8de8-8fd093cf9a46" />

-   **路由Routing**

每个节点，每个都存留一份路由表，所以当请求到任何一个节点时，ElasticSearch都有能力将请求转发到期望节点的shard进一步处理。

<img width="1368" height="772" alt="image" src="https://github.com/user-attachments/assets/de813d0c-7dd8-4097-a17a-e48438aee30b" />

## 一个真实的请求

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/ea748747-6641-443c-8de6-f4d91f927a59" />

-   **Query**

<img width="1374" height="762" alt="image" src="https://github.com/user-attachments/assets/48865e9c-e2c9-459d-bc84-b9a3c8d58f02" />

Query有一个类型filtered，以及一个multi\_match的查询

-   **Aggregation**

<img width="1378" height="768" alt="image" src="https://github.com/user-attachments/assets/a307c3b1-d75d-48b4-9fcd-f4901a181e7a" />

根据作者进行聚合，得到top10的hits的top10作者的信息

-   **请求分发**

这个请求可能被分发到集群里的任意一个节点

<img width="1372" height="766" alt="image" src="https://github.com/user-attachments/assets/f741fee6-66c5-4da6-97a3-d3d60ec7190d" />

-   **上帝节点**

<img width="1374" height="772" alt="image" src="https://github.com/user-attachments/assets/bb444182-2e0c-4437-b15d-bf0944516995" />

这时这个节点就成为当前请求的协调者（Coordinator），它决定： a) 根据索引信息，判断请求会被路由到哪个核心节点 b) 以及哪个副本是可用的 c) 等等

-   **路由**

<img width="1370" height="762" alt="image" src="https://github.com/user-attachments/assets/eb50f71a-a823-4dd1-8905-edc9c09e42d3" />

-   **在真实搜索之前**

ElasticSearch 会将Query转换成Lucene Query

<img width="1370" height="764" alt="image" src="https://github.com/user-attachments/assets/6976ee1e-d7c5-425a-99cb-cf9207b8146a" />

然后在所有的segment中执行计算

<img width="1372" height="760" alt="image" src="https://github.com/user-attachments/assets/d03fa31d-60a3-4ec7-b1d5-883178739fe9" />

对于Filter条件本身也会有缓存

<img width="1370" height="758" alt="image" src="https://github.com/user-attachments/assets/eda5d906-538b-467e-8795-2901ae3ead72" />

但queries不会被缓存，所以如果相同的Query重复执行，应用程序自己需要做缓存

<img width="1366" height="758" alt="image" src="https://github.com/user-attachments/assets/57824f2e-7fab-4d43-9bde-d4f56230ef68" />

所以，

a) filters可以在任何时候使用 b) query只有在需要score的时候才使用

-   **返回**

搜索结束之后，结果会沿着下行的路径向上逐层返回。

<img width="1368" height="762" alt="image" src="https://github.com/user-attachments/assets/bf38bb2c-fbb8-4ab4-9f80-17fa8048c112" />

<img width="1366" height="756" alt="image" src="https://github.com/user-attachments/assets/9aa03174-00b8-4fbd-8b3b-5c8eb60fe60b" />

<img width="1368" height="766" alt="image" src="https://github.com/user-attachments/assets/6f2c6706-e553-4cd0-9044-6cb2ab01e3f8" />

<img width="1372" height="768" alt="image" src="https://github.com/user-attachments/assets/7c8bef9a-7106-4e91-8a0b-7235717eec59" />

<img width="1372" height="764" alt="image" src="https://github.com/user-attachments/assets/0f2f4082-2ad7-43bf-b23a-bbdf84312a9c" />

## 参考来源

SlideShare: Elasticsearch From the Bottom Up

Youtube: Elasticsearch from the bottom up

Wiki: Document-term matrix

Wiki: Search engine indexing

Skip list

Standford Edu: Faster postings list intersection via skip pointers

StackOverflow: how an search index works when querying many words?

StackOverflow: how does lucene calculate intersection of documents so fast?

Lucene and its magical indexes

misspellings 2.0c: A tool to detect misspellings
